---
output: github_document
bibliography: Misc/references.bib
nocite: |
  @leekGeneralFrameworkMultiple2008,
  @stegleBayesianFrameworkAccount2010,@stegleUsingProbabilisticEstimation2012
  @mostafaviNormalizingRNAsequencingData2013
  
  @jolliffePrincipalComponentAnalysis2002,@johnsonAppliedMultivariateStatistical2007
  @bujaRemarksParallelAnalysis1992
  
  @gtexconsortiumGTExConsortiumAtlas2020
  @ongenFastEfficientQTL2016,@shabalinMatrixEQTLUltra2012
---


```{r,echo=FALSE}
setwd("~/2020.07.13_PEER/PCAForQTL")
```


We have shown that PCA outperforms popular hidden variable inference methods for QTL mapping (including SVA, PEER, and HCP) while being faster and more interpretable (preprint). In particular, compared to PEER, the most popular hidden variable inference method for QTL mapping currently, PCA performs better, is orders of magnitude faster and much easier to use and interpret, and offers convenient ways of choosing $K$ such as the elbow method and the Buja and Eyuboglu (BE) algorithm [-@bujaRemarksParallelAnalysis1992] (both of which we implement here in this package). In contrast, users of PEER need to rely on the claim that the performance of PEER does not deteriorate as $K$ increases [-@stegleBayesianFrameworkAccount2010; -@stegleUsingProbabilisticEstimation2012] (which we have shown to be a generally invalid claim) and often end up having to choose $K$ by maximizing the number of discoveries; not only is this approach of choosing $K$ extremely computationally expensive and theoretically unsound, we have also shown empirical evidence that it may yield inappropriate choices of $K$ (preprint). All in all, evidence suggests that PCA should be the go-to hidden variable inference method for QTL mapping.

Here we aim to provide some guidance on **how to use PCA** for hidden variable inference in QTL mapping and in particular **how to choose $K$** using the functions provided in this package. This package implements two simple, highly interpretable methods for choosing the number of PCs: an **automatic elbow detection method** (based on distance to the diagonal line) and the **BE algorithm** (a permutation-based approach) (see preprint for detailed descriptions of both methods). We decided to implement these methods ourselves after failing to find existing software packages that implement them well.


## 1. Installation

```{r,eval=FALSE}
#install.packages("devtools")
devtools::install_github("heatherjzhou/PCAForQTL")
```


## 2. How to run PCA

We start with the **fully processed** molecular phenotype matrix. In this tutorial, we use the fully processed gene expression matrix for colon (transverse) from GTEx V8 [-@gtexconsortiumGTExConsortiumAtlas2020] as an example. This gene expression matrix has been fully processed---TPM normalized, filtered, TMM normalized, and inverse normal transformed (see [link](https://gtexportal.org/home/documentationPage)). It can be obtained directly from [link](https://gtexportal.org/home/datasets) and is also made available under the folder named Example_Data in this repository (in a format that can be easily read into R).

First, download the example data set and load it into the environment (change the path as necessary on your device).

```{r}
dataGeneExpressionFP<-readRDS("./Example_Data/Colon_Transverse.v8.normalized_expression.rds") #25,379*372.
#The first four columns are chr, start, end, and gene_id.
```

Next, make sure that the data matrix is **observation by feature** and contains no auxiliary information.

```{r}
expr<-t(dataGeneExpressionFP[,-(1:4)]) #368*25,379. 368 samples, 25,379 genes.
# dim(expr)
```

Now we are ready to run PCA. In general, centering is almost always mandatory, and scaling is almost always preferred when running PCA. Since GTEx has already performed inverse normal transform on each feature, whether centering and scaling are performed on our example data does not affect the PCA result much. But we suggest **always centering and scaling** to be safe.

```{r}
prcompResult<-prcomp(expr,center=TRUE,scale.=TRUE) #This should take less than a minute.
PCs<-prcompResult$x #368*368. The columns are PCs.
# dim(PCs)
```

Note that the approach we use in this tutorial constitutes PCA_direct rather than PCA_resid (preprint). The two approaches perform similarly in our simulation studies, so we choose PCA_direct because it is simpler. In addition, PCA_direct can better hedge against the possibility that the known covariates are not actually important batch effects (because in PCA_direct, the known covariates do not affect the calculation of the PCs).

Optionally, you may inspect the proportion of variance explained by the PCs at this point. We omit this here because we will perform a more thorough analysis in the next section.

```{r}
# importanceTable<-summary(prcompResult)$importance
# PVEs<-importanceTable[2,]
# plot(PVEs,xlab="PC index",ylab="PVE")
```


## 3. How to choose $K$

There are four main functions in this package: `runElbow()`, `runBE()`, `makeScreePlot()`, and `filterKnownCovariates()`. The first three functions help us choose $K$. The last function will be discussed in the next section. For full details of these functions, run `library(PCAForQTL)` followed by `?runElbow`, `?runBE`, etc.

`runElbow()` implements an automatic elbow detection method (based on distance to the diagonal line). In our experience, the number of PCs chosen using this method **tends to match the visual elbow point reasonably well**. To run this function, simply input the previously obtained `prcompResult`. This method selects $K=12$ for our example data.

```{r}
resultRunElbow<-PCAForQTL::runElbow(prcompResult=prcompResult)
print(resultRunElbow)
```

`runBE()` implements the BE algorithm, a permutation-based approach for choosing $K$ in PCA. Intuitively, the BE algorithm retains PCs that explain more variance in the data than by random chance and discards those that do not. In our experience, the number of PCs chosen via BE **tends to signal an upper bound of the reasonable number of PCs to choose**. To run this function, we need to input the data matrix (must be observation by feature) and may optionally specify `B`, the number of permutations (default is 20), and `alpha`, the significance level (default is $0.05$). We may also specify `mc.cores` to change how many cores are used for parallel computing (default is `B` or the number of available cores minus 1, whichever is smaller). For reproducibility, Linux and Mac users must change the random number generator (RNG) type (unless `mc.cores` is 1) and set the seed. On the other hand, Windows users must set `mc.cores=1` to avoid error and set the seed for reproducibility (no need to change the RNG type). The BE method selects $K=29$ for our example data.

Linux and Mac users:

```{r}
RNGkind("L'Ecuyer-CMRG")
set.seed(1)
resultRunBE<-PCAForQTL::runBE(expr,B=20,alpha=0.05)
print(resultRunBE$numOfPCsChosen)
```

Windows users:

```{r,eval=FALSE}
set.seed(1) #No need to change the RNG type since mc.cores will be 1.
resultRunBE<-PCAForQTL::runBE(expr,B=20,alpha=0.05,
                              mc.cores=1)
print(resultRunBE$numOfPCsChosen)
```

After running `runElbow()` and/or `runBE()`, we recommend using `makeScreePlot()` to **visualize the selected $K$'s**. If you have candidate $K$'s chosen via other methods as well, you may also include them here.

```{r}
K_elbow<-resultRunElbow #12.
K_BE<-resultRunBE$numOfPCsChosen #29.
K_GTEx<-60 #GTEx uses 60 PEER factors, and they are almost identical to the top 60 PCs.
PCAForQTL::makeScreePlot(prcompResult,labels=c("Elbow","BE","GTEx"),values=c(K_elbow,K_BE,K_GTEx),
                         titleText="Colon - Transverse")
```

Using code similar to below, we may save the plot for each tissue type in order to compare across all tissue types before making a final decision on how to choose $K$.

```{r,eval=FALSE}
ggplot2::ggsave("./Colon_Transverse.jpg",width=16,height=11,unit="cm")
```



## 4. Using PCs in your QTL analysis

Last but not least, it is good practice to filter out the known covariates that are captured well by the inferred covariates (PCs) in order to avoid redundancy. GTEx V8 [-@gtexconsortiumGTExConsortiumAtlas2020] uses eight known covariates: the top five genotype PCs, WGS sequencing platform (HiSeq 2000 or HiSeq X), WGS library construction protocol (PCR-based or PCR-free), and donor sex. Similar to the gene expression matrix, these variables can be obtained directly from [link](https://gtexportal.org/home/datasets) and are also made available under the folder named Example_Data in this repository (in a format that can be easily read into R).

First, download the covariates and load them into the environment (change the path as necessary on your device). Make sure that the known covariate matrix is **observation by feature** and that the observations match those in the molecular phenotype matrix (and hence the PCs). If necessary, rename the known covariates to avoid potential confusion.

```{r}
dataCovariates<-readRDS("./Example_Data/Colon_Transverse.v8.covariates.rds") #368*68.
#The columns are the top five genotype PCs, 60 PEER factors, pcr, platform, and sex.

knownCovariates<-dataCovariates[,c(1:5,66:68)] #368*8. 368 samples, 8 known covariates.
identical(rownames(knownCovariates),rownames(expr)) #TRUE is good.
colnames(knownCovariates)[1:5]<-paste0("genotypePC",1:5) #This is to avoid potential confusion.
```

Suppose we have decided to use the number of PCs chosen via the automatic elbow detection method for our example data.

```{r}
PCsTop<-PCs[,1:K_elbow] #368*12.
```

Now we may use `filterKnownCovariates()` to **filter out the known covariates that are captured well by the top PCs** (unadjusted $R^2\geq 0.9$ by default). This function returns the known covariates that should be kept. We use unadjusted $R^2$ instead of adjusted $R^2$ because we do not want to penalize for model complexity here. The cutoff value may be customized using the argument `unadjustedR2_cutoff`.

```{r}
knownCovariatesFiltered<-PCAForQTL::filterKnownCovariates(knownCovariates,PCsTop,unadjustedR2_cutoff=0.9)
```

Finally, we may combine the remaining known covariates and the top PCs and use them as covariates in the QTL analysis. To avoid potential numerical inaccuracies in the QTL analysis, we may optionally scale the PCs to unit variance (though theoretically this would not change the QTL result from regression-based approaches such as FastQTL and Matrix eQTL).

```{r}
PCsTop<-scale(PCsTop) #Optional. Could be helpful for avoiding numerical inaccuracies.
covariatesToUse<-cbind(knownCovariatesFiltered,PCsTop)
```


## Citation

To acknowledge this package or this tutorial, please cite preprint. For questions, please feel free to email us (contact information can be found on preprint).



<!-- [-@stegleBayesianFrameworkAccount2010]. -->

## References
